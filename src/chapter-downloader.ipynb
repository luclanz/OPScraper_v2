{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immagine scaricata: images\\000.png\n",
      "Immagine scaricata: images\\001.png\n",
      "Immagine scaricata: images\\002.png\n",
      "Immagine scaricata: images\\003.png\n",
      "Immagine scaricata: images\\004.png\n",
      "Immagine scaricata: images\\005.png\n",
      "Immagine scaricata: images\\006.png\n",
      "Immagine scaricata: images\\007.png\n",
      "Immagine scaricata: images\\008.png\n",
      "Immagine scaricata: images\\009.png\n",
      "Immagine scaricata: images\\010.png\n",
      "Immagine scaricata: images\\011.png\n",
      "Immagine scaricata: images\\012.png\n",
      "Immagine scaricata: images\\013.png\n",
      "Immagine scaricata: images\\014.png\n",
      "Immagine scaricata: images\\015.png\n",
      "Immagine scaricata: images\\016.png\n",
      "Immagine scaricata: images\\017.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "# data variables\n",
    "\n",
    "link = \"https://tcbscans.com/chapters/7587/one-piece-chapter-1103?date=3-1-2024-23\"\n",
    "chapter = \"test\"\n",
    "\n",
    "def download_images(url, download_folder='images'):\n",
    "    # Creare una cartella per salvare le immagini\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    # Effettuare la richiesta GET all'URL fornito\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Errore nella richiesta GET. Codice di stato: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Utilizzare BeautifulSoup per analizzare l'HTML della pagina\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Trovare tutti i tag delle immagini\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    # Scaricare ciascuna immagine\n",
    "    for img_tag in img_tags:\n",
    "        img_url = img_tag.get('src')\n",
    "\n",
    "        # Creare l'URL completo utilizzando urljoin per gestire URL relativi\n",
    "        img_url = urljoin(url, img_url)\n",
    "\n",
    "        # Ottenere il nome del file dall'URL\n",
    "        img_filename = os.path.join(download_folder, f'{i:03d}.png')\n",
    "        i += 1\n",
    "\n",
    "        # Scaricare e salvare l'immagine\n",
    "        img_data = requests.get(img_url).content\n",
    "        with open(img_filename, 'wb') as img_file:\n",
    "            img_file.write(img_data)\n",
    "\n",
    "        print(f\"Immagine scaricata: {img_filename}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "download_images(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati delle immagini:\n",
      "[((650, 223), 58, '000.png'), ((1100, 1602), 177, '001.png'), ((1733, 1300), 256, '002.png'), ((2200, 1602), 256, '003.png'), ((1100, 1606), 33, '004.png'), ((1100, 1606), 19, '005.png'), ((1100, 1606), 16, '006.png'), ((2200, 1606), 34, '007.png'), ((1100, 1606), 16, '008.png'), ((1100, 1606), 6, '009.png'), ((1100, 1606), 16, '010.png'), ((1100, 1606), 18, '011.png'), ((1100, 1606), 16, '012.png'), ((1100, 1606), 23, '013.png'), ((1100, 1606), 17, '014.png'), ((1100, 1606), 6, '015.png'), ((2200, 1607), 19, '016.png'), ((2200, 1607), 155, '017.png')]\n",
      "una pagina avrà circa 1606 pixel di altezza\n",
      "una pagina avrà circa 1100 pixel di larghezza (singola)\n",
      "dopo un filtro sulla dimensione di altezza sono rimaste: 16 possibili immagini (comprese a colori)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_images(folder='images'):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            im = Image.open(img_path, 'r').convert('P')\n",
    "            data.append(tuple((im.size, len(Image.Image.getcolors(im)), filename)))\n",
    "            im.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "image_data = process_images()\n",
    "print(\"Dati delle immagini:\")\n",
    "print(image_data)\n",
    "\n",
    "import statistics\n",
    "\n",
    "# This func looks the data x and y and find the most likely dimension for the single page \n",
    "y_ = [image_data[j][0][1] for j in range(len(image_data))]\n",
    "y_ = statistics.mode(y_)\n",
    "print(f\"una pagina avrà circa {y_} pixel di altezza\")\n",
    "\n",
    "x_ = [image_data[j][0][0] for j in range(len(image_data))]\n",
    "x_ = statistics.mode(x_)\n",
    "print(f\"una pagina avrà circa {x_} pixel di larghezza (singola)\")\n",
    "\n",
    "filtered_data = list(filter(lambda y: y[0][1] > (y_ * 0.9) and y[0][1] < (y_ * 1.1), image_data))\n",
    "filtered_data = sorted(filtered_data, key = lambda x: x[1], reverse=False)\n",
    "print(f\"dopo un filtro sulla dimensione di altezza sono rimaste: {len(filtered_data)} possibili immagini (comprese a colori)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_color_image(image_path, color_threshold=20000):\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Converti l'immagine in una lista di colori distinti\n",
    "    unique_colors = list(set(img.getdata()))\n",
    "    #print(len(unique_colors))\n",
    "\n",
    "    # Determina se l'immagine è a colori basandoti sul numero di colori distinti\n",
    "    return len(unique_colors) > color_threshold\n",
    "\n",
    "def look_for_pages(dataList, targetPages, singlePageWidth):\n",
    "    nPages = 0\n",
    "    for i in range(len(dataList)):\n",
    "        img_path = os.path.join('images', dataList[i][2])\n",
    "        if is_color_image(img_path):\n",
    "            continue\n",
    "\n",
    "        if dataList[i][0][0] < (singlePageWidth * 1.1) and dataList[i][0][0] > (singlePageWidth * 0.9):\n",
    "            nPages += 1\n",
    "            #print(f\"{dataList[i][2]} counts as 1, {nPages}\")\n",
    "\n",
    "        if dataList[i][0][0] < (singlePageWidth * 2.2) and dataList[i][0][0] > (singlePageWidth * 1.8):\n",
    "            nPages += 2\n",
    "            #print(f\"{dataList[i][2]} counts as 2, {nPages}\")\n",
    "\n",
    "        if nPages == targetPages:\n",
    "            print(f\"Trovate {targetPages} pagine\")\n",
    "            for j in range(0,i):\n",
    "                img_path = os.path.join('images', dataList[j][2])\n",
    "                if is_color_image(img_path):\n",
    "                    return list()\n",
    "            return dataList[:i+1]\n",
    "\n",
    "    print(f\"Ricerca di {targetPages} pagine fallita.\")\n",
    "    return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricerca di 17 pagine fallita.\n",
      "Trovate 15 pagine\n",
      "000.png è spam\n",
      "001.png è spam\n",
      "002.png è spam\n",
      "003.png è spam\n",
      "017.png è spam\n"
     ]
    }
   ],
   "source": [
    "# ciclo per vedere quante pagine sono state trovate\n",
    "for i in (17, 15, 13):\n",
    "    a = look_for_pages(filtered_data, i, x_)\n",
    "    if len(a) > 0:\n",
    "        break\n",
    "\n",
    "if len(a) == 0:\n",
    "    raise Exception(\"Non son state trovare le pagine per un capitolo\")\n",
    "\n",
    "# eliminazione di tutte le immagini extra\n",
    "\n",
    "b = list(os.listdir(path='images'))\n",
    "\n",
    "for i in range(len(b)):\n",
    "\n",
    "    pageFound = 0\n",
    "\n",
    "    for j in range(len(a)):\n",
    "        if b[i] == a[j][2]:\n",
    "            pageFound = 1\n",
    "            break\n",
    "    \n",
    "    if b[i] != a[j][2]:\n",
    "        print(f\"{b[i]} è spam\")\n",
    "        img = os.path.join('images', b[i])\n",
    "        os.remove(img)\n",
    "\n",
    "a = process_images()    # need to run this function again because the order was lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "# find first page\n",
    "pageNumber = 1\n",
    "\n",
    "if a[0][0][0] > (x_ * 1.1) and a[0][0][0] < (x_ * 0.9):\n",
    "    raise Exception(\"Prima pagine non combacia. Errore nel motore di ricerca\")\n",
    "\n",
    "def addImage(list, name):\n",
    "    item = os.path.join('images', name)\n",
    "    imgg_ = Image.open(item)\n",
    "    img_ = ImageOps.expand(imgg_, border=10, fill='white')\n",
    "    imgg_ = img_.convert('RGB')\n",
    "    list.append(imgg_)\n",
    "    return list\n",
    "\n",
    "def addDoubleImage(list, name1, name2):\n",
    "    item1 = os.path.join('images', name1)\n",
    "    item2 = os.path.join('images', name2)\n",
    "    imgg1_ = Image.open(item1)\n",
    "    imgg2_ = Image.open(item2)\n",
    "    mergedImg = Image.new('RGB', (imgg1_.width + imgg2_.width, min(imgg1_.height, imgg2_.height)))\n",
    "    mergedImg.paste(imgg1_, (0, 0))\n",
    "    mergedImg.paste(imgg2_, (imgg1_.width, 0))\n",
    "    list.append(mergedImg)\n",
    "    return list\n",
    "\n",
    "# pdf\n",
    "imageListPdf = []\n",
    "\n",
    "# loop for the other images (skip the first one since it will automatically added in the last step)\n",
    "doubleTag = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 006.png and 005.png as double\n",
      "added 007.png as single\n",
      "added 009.png and 008.png as double\n",
      "added 011.png and 010.png as double\n",
      "added 013.png and 012.png as double\n",
      "added 015.png and 014.png as double\n",
      "added 016.png as single\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(a)):\n",
    "    if a[i][0][0] < (x_ * 2.2) and a[i][0][0] > (x_ * 1.8):\n",
    "        print(f\"added {a[i][2]} as single\")\n",
    "        imageListPdf = addImage(imageListPdf, a[i][2])\n",
    "        doubleTag = 0\n",
    "    else:\n",
    "        if doubleTag == 0:\n",
    "            imageListPdf = addDoubleImage(imageListPdf, a[i+1][2], a[i][2])\n",
    "            print(f\"added {a[i+1][2]} and {a[i][2]} as double\")\n",
    "            doubleTag = 1\n",
    "        else:\n",
    "            doubleTag = 0\n",
    "\n",
    "item = os.path.join('images', a[0][2])\n",
    "img = Image.open(item)\n",
    "img.save(f'{chapter}.pdf', save_all=True, append_images=imageListPdf)\n",
    "\n",
    "for item in os.listdir('images'):\n",
    "    item = os.path.join('images', item)\n",
    "    os.remove(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
